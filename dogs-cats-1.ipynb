{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these command to download the dataset:\n",
    "```sh\n",
    "wget http://files.fast.ai/data/dogscats.zip\n",
    "unzip dogscats.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\tsample\ttest1  train  valid\r\n"
     ]
    }
   ],
   "source": [
    "!ls dogscats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torch.optim as opt\n",
    "import torch.nn as nn\n",
    "from torch.utils import data as td\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as tr\n",
    "from torchvision.models import resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = tr.Compose([\n",
    "    tr.RandomResizedCrop(224),\n",
    "    tr.RandomHorizontalFlip(),\n",
    "    tr.ToTensor(), \n",
    "    tr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = tv.datasets.ImageFolder('dogscats/train', transform=train_trans)\n",
    "train_loader = td.DataLoader(train_iter, batch_size=16, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1437"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_num_imgs = !find dogscats/valid/ -type f  | wc -l\n",
    "valid_num_imgs = int(valid_num_imgs[0])\n",
    "valid_num_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_trans = tr.Compose([\n",
    "    tr.CenterCrop(224), \n",
    "    tr.ToTensor(), \n",
    "    tr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iter = tv.datasets.ImageFolder('dogscats/valid', transform=valid_trans)\n",
    "valid_loader = td.DataLoader(valid_iter, batch_size=16, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = resnet34(pretrained=True)\n",
    "layers = list(net.children())\n",
    "last_layer = layers[-1]\n",
    "last_layer.in_features, last_layer.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in net.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ult = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_features=last_layer.in_features),\n",
    "    nn.Dropout(p=.5),\n",
    "    nn.Linear(in_features=last_layer.in_features, out_features=2)\n",
    ")\n",
    "net.fc = ult\n",
    "# net.fc = nn.Linear(in_features=last_layer.in_features, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = opt.Adam(net.fc.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct= 0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicts = torch.max(outputs, 1)\n",
    "            total += labels.size()[0]\n",
    "            correct += (predicts == labels).sum().cpu().item()\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ad480855504892a4746b85e99b9dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1437), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "419.43814798630774 0.966\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for data in tqdm.tqdm_notebook(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(running_loss, accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left to do:\n",
    "1. ~~Freeze lower resnet layers~~\n",
    "1. ~~Add validation set and accuracy~~\n",
    "1. Why accuracy is slow? Cache validation set and move to device\n",
    "1. ~~Improve accuracy!~~ -> Moved to resnet101, resnet 34 was too small (?)\n",
    "1. Smaller batches?\n",
    "1. Why is resnet34 from torchvision different from the one in fast.ai?\n",
    "1. Print loss and accuracy in tdqm\n",
    "1. Better transformations, take from fast.ai\n",
    "1. LR scheduling and optimization -> Currently second epoch losses accuracy\n",
    "1. Different optimizers and hyper-parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
