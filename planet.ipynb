{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclassification using Kaggle Planet data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning and adapted to PyTorch 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as tr\n",
    "from torchvision.models import resnet34\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = 'planet/train-jpg/'\n",
    "IMG_EXT = '.jpg'\n",
    "TRAIN_DATA = 'planet/train_v2.csv'\n",
    "ORIG_IMG_SIZE = 256\n",
    "RESNET_ING_SIZE = 224\n",
    "DEST_IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.image_name\n",
    "tags = df['tags'].str.split()\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(tags).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaggleAmazonDataset(Dataset):\n",
    "    def __init__(self, X, Y, img_path, img_ext, transform=None, mlb=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path + self.X.iloc[index] + self.img_ext)\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = torch.from_numpy(self.Y[index])\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = tr.Compose([tr.Resize(DEST_IMG_SIZE),tr.ToTensor()])\n",
    "dset_train = KaggleAmazonDataset(X_train, Y_train, IMG_PATH, IMG_EXT, transformations)\n",
    "dset_test  = KaggleAmazonDataset(X_test,  Y_test,  IMG_PATH, IMG_EXT, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dset_train,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, DEST_IMG_SIZE, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(DEST_IMG_SIZE, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(2304, 256)\n",
    "        self.fc2 = nn.Linear(256, 17)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "model = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx > 0 and batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [2560/36431 (7%)]\tLoss: 0.678571\n",
      "Train Epoch: 0 [5120/36431 (14%)]\tLoss: 0.673678\n",
      "Train Epoch: 0 [7680/36431 (21%)]\tLoss: 0.668038\n",
      "Train Epoch: 0 [10240/36431 (28%)]\tLoss: 0.659702\n",
      "Train Epoch: 0 [12800/36431 (35%)]\tLoss: 0.651008\n",
      "Train Epoch: 0 [15360/36431 (42%)]\tLoss: 0.640872\n",
      "Train Epoch: 0 [17920/36431 (49%)]\tLoss: 0.626938\n",
      "Train Epoch: 0 [20480/36431 (56%)]\tLoss: 0.611904\n",
      "Train Epoch: 0 [23040/36431 (63%)]\tLoss: 0.588924\n",
      "Train Epoch: 0 [25600/36431 (70%)]\tLoss: 0.563020\n",
      "Train Epoch: 0 [28160/36431 (77%)]\tLoss: 0.518851\n",
      "Train Epoch: 0 [30720/36431 (84%)]\tLoss: 0.480779\n",
      "Train Epoch: 0 [33280/36431 (91%)]\tLoss: 0.434471\n",
      "Train Epoch: 0 [35840/36431 (98%)]\tLoss: 0.392184\n"
     ]
    }
   ],
   "source": [
    "train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [2560/36431 (7%)]\tLoss: 0.354426\n",
      "Train Epoch: 1 [5120/36431 (14%)]\tLoss: 0.341211\n",
      "Train Epoch: 1 [7680/36431 (21%)]\tLoss: 0.329356\n",
      "Train Epoch: 1 [10240/36431 (28%)]\tLoss: 0.321545\n",
      "Train Epoch: 1 [12800/36431 (35%)]\tLoss: 0.310725\n",
      "Train Epoch: 1 [15360/36431 (42%)]\tLoss: 0.310140\n",
      "Train Epoch: 1 [17920/36431 (49%)]\tLoss: 0.316663\n",
      "Train Epoch: 1 [20480/36431 (56%)]\tLoss: 0.312762\n",
      "Train Epoch: 1 [23040/36431 (63%)]\tLoss: 0.314562\n",
      "Train Epoch: 1 [25600/36431 (70%)]\tLoss: 0.310925\n",
      "Train Epoch: 1 [28160/36431 (77%)]\tLoss: 0.313107\n",
      "Train Epoch: 1 [30720/36431 (84%)]\tLoss: 0.304963\n",
      "Train Epoch: 1 [33280/36431 (91%)]\tLoss: 0.298455\n",
      "Train Epoch: 1 [35840/36431 (98%)]\tLoss: 0.303378\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4048"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dset_test,\n",
    "    batch_size=len(dset_test),\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, y_true = next(iter(test_loader))\n",
    "    y_pred = (model(x.cuda()).cpu() >= 0.5).long().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136116600790514"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true.numpy(), y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5668674698795181"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true.numpy(), y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Delete of given test set, it is useless\n",
    "1. Data augmentation!\n",
    "1. Resize to 64 instead of 32\n",
    "1. Rehearse fast.ai \"ResNet from scrach\" - loading resnet does not work as advertized\n",
    "1. Different loss functions for multilabel (what's the difference?)\n",
    "1. Batching on validation, concat `y_pred` and `y_true` and submit to sklean metric\n",
    "1. tqdm progress bars instead of printouts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
